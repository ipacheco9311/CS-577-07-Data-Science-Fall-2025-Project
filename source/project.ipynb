{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Set Up for Project Imports\n",
   "id": "73acc9f141075611"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import sys\n",
    "from pathlib import Path"
   ],
   "id": "33a7e5543a6aea8a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "source_directory = Path.cwd()\n",
    "ROOT = source_directory.parent\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(ROOT))"
   ],
   "id": "26b64af0f12ae2ad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Auto-reload code changes\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "id": "9b8f4360f956b974",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Imports",
   "id": "53bce69ec8ae7cf3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from data.api import UcIrvineAPI, UcIrvineDatasetIDs\n",
    "import data.wrangling_utils\n",
    "import pandas\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (\n",
    "    r2_score,\n",
    "    mean_squared_error,\n",
    "    mean_absolute_error,\n",
    "    mean_absolute_percentage_error,\n",
    "    median_absolute_error,\n",
    ")"
   ],
   "id": "67358bb76e0e3250",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "pandas.set_option('display.max_colwidth', None)  # show all text in cells\n",
    "# pandas.set_option(\"display.max_rows\", 100_000)\n",
    "pandas.options.mode.copy_on_write = True\n",
    "pandas.set_option('display.float_format', lambda x: '%.2f' % x)"
   ],
   "id": "8c220ffa268b6e71",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# UcIrvine Data",
   "id": "418a7487f08fecdd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "uci = UcIrvineAPI.fetch_dataset(repo_id=UcIrvineDatasetIDs.Apartment_For_Rent_Classified.value)\n",
    "uci_df: pandas.DataFrame = uci.data.original.reset_index()"
   ],
   "id": "e211d935a855b77d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "uci_df.describe()",
   "id": "288c8e49a1c0de1d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "uci_df.shape",
   "id": "7d04d75b33378b1a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Data Cleaning",
   "id": "73c73a3f02fe5d92"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "clean_uci_df: pandas.DataFrame = data.wrangling_utils.clean(uci_df)",
   "id": "4b7f4fdbe8b5a317",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "clean_uci_df.info()",
   "id": "854b0659625dbafa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Exploratory Data Analysis\n",
   "id": "f0b1d1aa6ca33dcd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Top 5 Listing Sources",
   "id": "663abdec93143a12"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sources_df = clean_uci_df.groupby(['source']).size().reset_index(name='count').sort_values(by='count', ascending=False)\n",
    "sources_df.head(5)"
   ],
   "id": "eea0427e3f10ba61",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Distribution of Count of Listings per State",
   "id": "7e8eff0b9ed14456"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "clean_uci_df.sort_values(by='state', inplace=True)",
   "id": "2a768539c4a05046",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig, axes = plt.subplots(1, 1, figsize=(12, 12))\n",
    "ax = sns.countplot(data=clean_uci_df, x='state', width=0.5)\n",
    "\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container)\n",
    "\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()"
   ],
   "id": "ff8cbaf4536132e0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Descriptive Statistics of all listings",
   "id": "dd4ecc47f7772a4c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "clean_uci_df.describe()",
   "id": "741ac628560f9cf6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "An apartment with 9 bedrooms, a monthly cost of $120,000, and 50,000 square feet? Is this actually an apartment? Let's examine the listings by combinations of bedrooms and bathrooms, and distributions of prices and square footage.. It will give insight on the type of properties in our data.",
   "id": "b4d6c2237296cfe8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Removing Noise",
   "id": "61021ba267762473"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "filtered_df = clean_uci_df.groupby(['bedrooms', 'bathrooms']).size().reset_index(name='count')\n",
    "filtered_df"
   ],
   "id": "14a40bb8ef71c1ed",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "It appears studios, townhomes, houses, mansions, or penthouses are also in the data. Some properties don't even have a bedroom? Other properties have 4+ bedrooms and bathrooms? That doesn't make sense for a typical apartment.",
   "id": "2596d914efd2dea9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "min_bedrooms = 1\n",
    "max_bedrooms = 3\n",
    "filtered_df = clean_uci_df[(clean_uci_df['bedrooms'] >= min_bedrooms) & (clean_uci_df['bedrooms'] <= max_bedrooms) & (clean_uci_df['bathrooms'] <= 3)]\n",
    "filtered_df.describe()"
   ],
   "id": "9e410debd27ac3b1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Why is 3 bed and 3 bath priced at $33,0000? That sees overpriced even for a luxury apartment. Let's examine the distribution of listing prices for our data.",
   "id": "72013236f870a367"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "price_distribution_df = filtered_df.groupby(['price']).size().reset_index(name='count')\n",
    "sns.histplot(price_distribution_df['price'], bins=50)\n",
    "plt.xlim(price_distribution_df['price'].min(), price_distribution_df['price'].max())\n",
    "plt.show()"
   ],
   "id": "32545e401af27ed0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The distribution of prices is unimodal, and it is strongly right skewed where most the data is centered around 2,000-3,0000 USD. There are extreme outliers of 10,000-30,000. Maybe luxurious apartments/penthouse are causing this.",
   "id": "7cfe5d2992703ff2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "min_price = 500\n",
    "max_price = 10000\n",
    "filtered_df = filtered_df[(filtered_df['price'] >= min_price) & (filtered_df['price'] <= max_price)]\n",
    "filtered_df.describe()"
   ],
   "id": "5ad9baae010e6816",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now let's examine the distribution of prices again.",
   "id": "e4692ed0a7b61230"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "price_distribution_df = filtered_df.groupby(['price']).size().reset_index(name='count')\n",
    "sns.histplot(price_distribution_df['price'], bins=50)\n",
    "plt.show()"
   ],
   "id": "73ed4aca0b8f69b8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The distribution of the listing prices is still right skewed but we got rid of some noise. Now let's examine the distribution of the square footage of the listings since ~5,000 square foot apartment still seems large for a max 3 bedroom and 3 bathroom apartment.",
   "id": "6fbaa6e43ff76dd9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sqft_distribution_df = filtered_df.groupby(['square_feet']).size().reset_index(name='count')\n",
    "sns.histplot(sqft_distribution_df['square_feet'], bins=24)\n",
    "plt.xlim(sqft_distribution_df['square_feet'].min(), sqft_distribution_df['square_feet'].max())\n",
    "plt.show()"
   ],
   "id": "d2e510803df2ff81",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "max_sq_ft = 4000\n",
    "filtered_df = filtered_df[(filtered_df['square_feet'] <= max_sq_ft)]\n",
    "filtered_df.describe()"
   ],
   "id": "763508388033c45e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sns.histplot(filtered_df['square_feet'], bins=24)\n",
    "plt.xlim(filtered_df['square_feet'].min(), filtered_df['square_feet'].max())\n",
    "plt.show()"
   ],
   "id": "7668bc9e55e7266e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#select monthly price\n",
    "cleaned_subset_df = clean_uci_df[(clean_uci_df['bedrooms'] >= min_bedrooms) & (clean_uci_df['bedrooms'] <= max_bedrooms) & (clean_uci_df['bathrooms'] <= 3) & (filtered_df['price'] >= min_price) & (filtered_df['price'] <= max_price) & (clean_uci_df['square_feet'] <= max_sq_ft) & (clean_uci_df['price_type'] == 'monthly') & (clean_uci_df['state'] is not None)]\n",
    "\n",
    "#select only these columns\n",
    "cleaned_subset_df = cleaned_subset_df[['bathrooms', 'bedrooms', 'price', 'square_feet', 'state', 'latitude', 'longitude', 'cityname']]\n",
    "\n",
    "cleaned_subset_df = cleaned_subset_df.dropna()"
   ],
   "id": "56c559fb659a0c32",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "cleaned_subset_df.describe()",
   "id": "2cab1b54f8a6d4ae",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "cleaned_subset_df.shape",
   "id": "85a4d578d9d8aa02",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "percent_change = (1.0 - (cleaned_subset_df.shape[0] / uci_df.shape[0])) * 100\n",
    "print(f\"Percent change {percent_change:.3f}%\")"
   ],
   "id": "2d1d2f1684026264",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## More Skewness Analysis",
   "id": "3b5a6c420e108688"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "cleaned_subset_df[['price', 'square_feet']].skew()",
   "id": "71038b66f31fd914",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "| Feature       | Skew     | Interpretation            | Action               |\n",
    "| ------------- |----------|---------------------------|----------------------|\n",
    "| `price`       | **2.28** | **Strongly right-skewed** | Should transform     |\n",
    "| `square_feet` | **1.17** | **Strongly right-skewed** | Should transform     |\n"
   ],
   "id": "e04f0f10c2608711"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Most the data is small to large apartments prices around $1,500 - 3,000 but a handful of extremely underpriced/overpriced apartments are skewing the data. So we will perform a log transformation to reduce their influence.",
   "id": "936c2ca86e720f77"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "cleaned_subset_df['price_log'] = np.log1p(cleaned_subset_df['price'])\n",
    "cleaned_subset_df['square_feet_log'] = np.log1p(cleaned_subset_df['square_feet'])\n",
    "cleaned_subset_df[['price_log', 'square_feet_log']].skew()"
   ],
   "id": "191a5d41952eb94",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "| Feature       | Skew              | Interpretation         |\n",
    "|---------------|-------------------|-------------------------|\n",
    "| `price`       | **2.28 -> 0.36**  | **Weakly right-skewed** |\n",
    "| `square_feet` | **1.17 -> -0.21** | **Weakly left-skewed**  |"
   ],
   "id": "9d6e02e88a799e28"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sns.histplot(cleaned_subset_df['price_log'], bins=24)\n",
    "plt.xlim(cleaned_subset_df['price_log'].min(), cleaned_subset_df['price_log'].max())\n",
    "plt.show()"
   ],
   "id": "83ad1804f245ad5d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sns.histplot(cleaned_subset_df['square_feet_log'], bins=24)\n",
    "plt.xlim(cleaned_subset_df['square_feet_log'].min(), cleaned_subset_df['square_feet_log'].max())\n",
    "plt.show()"
   ],
   "id": "b3b78d44e4427cff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "grid = sns.pairplot(cleaned_subset_df[['bathrooms', 'bedrooms', 'price_log', 'square_feet_log']], kind='scatter', corner=True)",
   "id": "42b409fecca15de4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "There only seems a weak linear relationship between log_price and square_feet_log.",
   "id": "d2c575001e42800b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "correlation = cleaned_subset_df[['bathrooms', 'bedrooms', 'price_log', 'square_feet_log']].corr(numeric_only=True)",
   "id": "b5f2a9a636491b4d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "correlation",
   "id": "1ef8c4c5f4a39c05",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.title(\"Correlation Heatmap\", fontsize=14)\n",
    "sns.heatmap(correlation, annot=True, linewidths=0.5, cmap='mako')\n",
    "plt.show()"
   ],
   "id": "bf12fee9ceee5c66",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Variable Types\n",
    "\n",
    "- Discrete / ordinal: bedrooms, bathrooms — integer counts\n",
    "- Continuous: price_log, square_feet_log — continuous and normalized\n",
    "- We used Pearson correlation, the relationships involving discrete counts are approximate linear associations, not strict parametric correlations — but they’re still informative here since the discrete values are ordered and range reasonably (0–9).\n",
    "\n",
    "\n",
    "| Pair                            | Correlation | Interpretation                                                                                                                                            |\n",
    "| ------------------------------- |-------------| --------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| **bathrooms ↔ bedrooms**        | **0.65**    | Strong positive relationship — homes with more bedrooms usually have more bathrooms.                                                                      |\n",
    "| **bathrooms ↔ square_feet_log** | **0.68**    | Strong positive correlation — larger houses naturally have more bathrooms.                                                                                |\n",
    "| **bedrooms ↔ square_feet_log**  | **0.66**    | Same strong pattern — larger homes have more bedrooms.                                                                                                    |\n",
    "| **price_log ↔ square_feet_log** | **0.36**    | Moderate positive relationship — price generally rises with size, but not perfectly (other factors matter).                                               |\n",
    "| **price_log ↔ bathrooms**       | **0.31**    | Mild correlation — price increases somewhat with bathroom count, but not linearly.                                                                        |\n",
    "| **price_log ↔ bedrooms**        | **0.21**    | Weak correlation — price doesn’t increase as predictably with bedroom count, possibly because extra bedrooms add less marginal value than square footage. |\n"
   ],
   "id": "11858c9eda38c9b3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Skewnesss by State",
   "id": "3578f5aa2af6ebfe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "state_groups = cleaned_subset_df.groupby(\"state\")\n",
    "for state, group in state_groups:\n",
    "    numeric_df = group[[\"bathrooms\", \"bedrooms\", \"price_log\", \"square_feet_log\"]]\n",
    "    skew_per_state = numeric_df.skew()\n",
    "    print(f\"{state}\\n{skew_per_state}\\n\")"
   ],
   "id": "580bd40a3e55a43e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Correlation by State",
   "id": "79c6418525d05a40"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "correlation_by_state = {}\n",
    "for state, group in state_groups:\n",
    "    numeric_df = group[[\"bathrooms\", \"bedrooms\", \"price_log\", \"square_feet_log\"]]\n",
    "    correlation_by_state[state] = numeric_df.corr()"
   ],
   "id": "fa294c3d5604945c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "n_states = len(correlation_by_state.keys())\n",
    "# Grid size (fits 51)\n",
    "rows = 8\n",
    "cols = 7\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(cols * 3, rows * 3))\n",
    "axes = axes.flatten()\n",
    "for idx, state in enumerate(correlation_by_state.keys()):\n",
    "    ax = axes[idx]\n",
    "    corr = correlation_by_state[state]\n",
    "\n",
    "    sns.heatmap(\n",
    "        corr,\n",
    "        ax=ax,\n",
    "        cmap=\"mako\",\n",
    "        square=True,\n",
    "        xticklabels=True,\n",
    "        yticklabels=True,\n",
    "        annot=True,\n",
    "        cbar=False\n",
    "    )\n",
    "\n",
    "    ax.set_title(state, fontsize=14)\n",
    "    ax.tick_params(axis='x', labelrotation=45, labelsize=10)\n",
    "    ax.tick_params(axis='y', labelrotation=45, labelsize=10)\n",
    "\n",
    "# Hide any unused subplot cells\n",
    "for j in range(len(correlation_by_state.keys()), len(axes)):\n",
    "    axes[j].axis(\"off\")\n",
    "\n",
    "fig.suptitle(\"Correlation Matrices by State\", fontsize=18)\n",
    "plt.tight_layout(rect=(0.0, 0.0, 1.0, 0.99))\n",
    "plt.show()"
   ],
   "id": "7544e94844df4460",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# K Means Clustering",
   "id": "47fc083057d5c1ef"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "clusterer = KMeans(n_clusters=30, random_state=42)\n",
    "cleaned_subset_df['geo_cluster'] = clusterer.fit_predict(cleaned_subset_df[['latitude', 'longitude']])"
   ],
   "id": "b8f8f2a0fa49a179",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "ax = sns.scatterplot(\n",
    "    data=cleaned_subset_df,\n",
    "    x=\"longitude\",\n",
    "    y=\"latitude\",\n",
    "    hue=\"geo_cluster\",\n",
    "    palette=\"tab20\",\n",
    "    s=30\n",
    ")\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "plt.legend(\n",
    "    handles=handles,\n",
    "    labels=labels,\n",
    "    title=\"Cluster\",\n",
    "    ncol=3,\n",
    "    bbox_to_anchor=(1,1),\n",
    "    loc=\"upper left\"\n",
    ")\n",
    "\n",
    "plt.show()"
   ],
   "id": "da7a338625a96f07",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X = cleaned_subset_df[['square_feet_log', 'bedrooms', 'bathrooms', 'state', 'geo_cluster', 'cityname']]\n",
    "y = cleaned_subset_df['price_log']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"square_feet_log_poly\", PolynomialFeatures(degree=2, include_bias=False), ['square_feet_log']),\n",
    "    ('structura_linear', 'passthrough', ['bedrooms', 'bathrooms']),\n",
    "    ('city_encoded', OneHotEncoder(handle_unknown='ignore'), ['cityname']),\n",
    "    ('neighborhood_cluster_encoded', OneHotEncoder(handle_unknown='ignore'), ['geo_cluster'])\n",
    "])\n",
    "\n",
    "model = Pipeline([\n",
    "    ('preprocess', preprocessor),\n",
    "    ('linreg', LinearRegression()),\n",
    "])\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# ==========================\n",
    "# 7. Metrics helper (includes Adjusted R²)\n",
    "# ==========================\n",
    "def adjusted_r2(y_true, y_pred, n_features: int) -> float:\n",
    "    \"\"\"Compute Adjusted R² given predictions and number of original features.\"\"\"\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    n = len(y_true)\n",
    "    p = n_features\n",
    "    return 1 - (1 - r2) * (n - 1) / (n - p - 1)\n",
    "\n",
    "\n",
    "def print_regression_metrics(split_name, y_true, y_pred, n_features: int):\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    adj_r2 = adjusted_r2(y_true, y_pred, n_features)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_true, y_pred)\n",
    "    med_ae = median_absolute_error(y_true, y_pred)\n",
    "\n",
    "    print(f\"=== {split_name} Metrics ===\")\n",
    "    print(f\"R²:              {r2:.2f}\")\n",
    "    print(f\"Adjusted R²:     {adj_r2:.2f}\")\n",
    "    print(f\"MSE:             {mse:.2f}\")\n",
    "    print(f\"RMSE:            {rmse:.2f}\")\n",
    "    print(f\"MAE:             {mae:.2f}\")\n",
    "    print(f\"MAPE:            {mape:.2f}\")\n",
    "    print(f\"Median Abs Err:  {med_ae:.2f}\")\n",
    "    print()\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# 8. Interpret real-world error from log-space metrics\n",
    "# ==========================\n",
    "def interpret_log_error_metrics(split_name, y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Interpret log-space error metrics in real price terms.\n",
    "    Assumes y_true and y_pred are log(price).\n",
    "    \"\"\"\n",
    "    rmse_log = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae_log = mean_absolute_error(y_true, y_pred)\n",
    "    med_ae_log = median_absolute_error(y_true, y_pred)\n",
    "\n",
    "    # Convert log errors to multiplicative factors\n",
    "    rmse_factor = np.exp(rmse_log)\n",
    "    mae_factor = np.exp(mae_log)\n",
    "    med_factor = np.exp(med_ae_log)\n",
    "\n",
    "    rmse_pct = (rmse_factor - 1.0) * 100.0\n",
    "    mae_pct = (mae_factor - 1.0) * 100.0\n",
    "    med_pct = (med_factor - 1.0) * 100.0\n",
    "\n",
    "    print(f\"=== {split_name} Real-World Error Interpretation ===\")\n",
    "    print(f\"Typical error (RMSE):    x {rmse_factor:.3f}  (predictions are typically off by ~{rmse_pct:.1f}% in true price)\")\n",
    "    print(f\"Average error (MAE):     x {mae_factor:.3f}  (On average, predictions are off by ~{mae_pct:.1f}% in true price)\")\n",
    "    print(f\"Typical core error (Median AE): x {med_factor:.3f}  (For half the homes, predictions are off within ~{med_pct:.1f}% in true price)\")\n",
    "    print()\n",
    "\n",
    "\n",
    "# number of ORIGINAL features (bathrooms, bedrooms, sqft_log, state)\n",
    "n_features = model.named_steps[\"preprocess\"].transform(X_train).shape[1]\n",
    "\n",
    "print_regression_metrics(\"Train\", y_train, y_train_pred, n_features)\n",
    "print_regression_metrics(\"Test\",  y_test,  y_test_pred,  n_features)\n",
    "\n",
    "interpret_log_error_metrics(\"Train\", y_train, y_train_pred)\n",
    "interpret_log_error_metrics(\"Test\",  y_test,  y_test_pred)\n"
   ],
   "id": "dab6a042b29d7c2a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "| Metric               | Train Value | Test Value | Interpretation                                                                                                                   |\n",
    "|----------------------|-------------|------------|----------------------------------------------------------------------------------------------------------------------------------|\n",
    "| **R²**               | 0.78        | 0.76       | % of variance explained. Model captures ~78% of training variation and ~76% of unseen variation **strong fit, low overfitting**. |\n",
    "| **MSE**              | 0.04        | 0.04       | Average squared error. Test MSE only slightly higher **good generalization**.                                                    |\n",
    "| **RMSE**             | 0.20        | 0.21       | Typical prediction error magnitude, ~20–21% deviation in normalized/log scale.                                                   |\n",
    "| **MAE**              | 0.15        | 0.15       | Average absolute error, predictions off by ~15%.                                                                                 |\n",
    "| **MAPE**             | 0.02        | 0.02       | Mean Absolute Percentage Error ~2% if target is scaled, or ~2% error in/log space. Very low **consistent accuracy**.             |\n",
    "| **Median Abs Error** | 0.11        | 0.11       | Half of predictions are within **11% error**. Indicates tight, stable core accuracy.                                             |\n"
   ],
   "id": "d4432e0b51859a6e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_resid = y_train - y_train_pred\n",
    "test_resid  = y_test  - y_test_pred"
   ],
   "id": "6d517fdc6c7741cf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Build DataFrames for easy plotting\n",
    "train_df = pandas.DataFrame({\n",
    "    \"Fitted\": y_train_pred,\n",
    "    \"Residual\": train_resid,\n",
    "    \"Split\": \"Train\"\n",
    "})\n",
    "\n",
    "test_df = pandas.DataFrame({\n",
    "    \"Fitted\": y_test_pred,\n",
    "    \"Residual\": test_resid,\n",
    "    \"Split\": \"Test\"\n",
    "})\n",
    "\n",
    "resid_df = pandas.concat([train_df, test_df], ignore_index=True)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 8))\n",
    "sns.scatterplot(\n",
    "    data=resid_df,\n",
    "    x=\"Fitted\",\n",
    "    y=\"Residual\",\n",
    "    hue=\"Split\",\n",
    "    alpha=0.5\n",
    ")\n",
    "\n",
    "plt.axhline(0, linestyle=\"--\", color=\"black\", linewidth=1)\n",
    "plt.title(\"Residuals vs Fitted\")\n",
    "plt.xlabel(\"Fitted\")\n",
    "plt.ylabel(\"Residual\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "417cd7e5eaa65dd3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# DO NOT DELETE MIGHT NEED\n",
    "# import json\n",
    "# s = cleaned_uci_df['bathrooms'].explode()\n",
    "# global_counts = s.value_counts().to_dict()\n",
    "# global_counts\n",
    "# print(f'BAD_DATA: {json.dumps(BAD_DATA['cityname'], indent=2)}')  # CHANGE COL\n",
    "# uci_df[\"state_full\"] = uci_df[\"state\"].str.upper().map(STATE_MAP)\n",
    "# print(uci_df.shape)\n",
    "# uci_df.dropna(subset=[\"state_full\"], inplace=True)\n",
    "# uci_df.shape"
   ],
   "id": "b8d3584b5226cf12",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Simple Linear Regression",
   "id": "dce5a7d01034fcaf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "lin_regression_residuals = {}\n",
    "for state, group in state_groups:\n",
    "    # choose numeric columns only\n",
    "    X = group[[\"bathrooms\", \"bedrooms\", \"square_feet_log\"]]\n",
    "    y = group[['price_log']]\n",
    "    model = LinearRegression()\n",
    "    model.fit(X, y)\n",
    "    # Predictions and residuals\n",
    "    y_pred = model.predict(X)\n",
    "    residuals = y - y_pred\n",
    "    lin_regression_residuals[state] = y_pred, residuals"
   ],
   "id": "7da1a64b7c5c96d7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Grid size (fits 51)\n",
    "rows = 8\n",
    "cols = 7\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(cols * 6, rows * 6))\n",
    "axes = axes.flatten()\n",
    "for idx, state in enumerate(lin_regression_residuals.keys()):\n",
    "    ax = axes[idx]\n",
    "    y_pred, residuals = lin_regression_residuals[state]\n",
    "    ax.scatter(y_pred, residuals)\n",
    "    ax.axhline(0, color='red', linestyle='--', linewidth=2)\n",
    "    ax.set_title(state, fontsize=14)\n",
    "    ax.set_xlabel('Predicted price_log', fontsize=10)\n",
    "    ax.set_ylabel('Residuals', fontsize=10)\n",
    "    ax.set_title(state, fontsize=14)\n",
    "# Hide any unused subplot cells\n",
    "for j in range(len(lin_regression_residuals.keys()), len(axes)):\n",
    "    axes[j].axis(\"off\")\n",
    "plt.tight_layout(rect=(0.0, 0.0, 1.0, 0.99))\n",
    "plt.show()"
   ],
   "id": "2c6be007861f7ecb",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
