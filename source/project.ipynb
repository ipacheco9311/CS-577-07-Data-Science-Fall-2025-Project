{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Set Up for Project Imports\n",
   "id": "73acc9f141075611"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#import sys\n",
    "#from pathlib import Path"
   ],
   "id": "33a7e5543a6aea8a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#source_directory = Path.cwd()\n",
    "#ROOT = source_directory.parent\n",
    "#if str(ROOT) not in sys.path:\n",
    "#    sys.path.insert(0, str(ROOT))"
   ],
   "id": "26b64af0f12ae2ad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "## Auto-reload code changes\n",
    "#%load_ext autoreload\n",
    "#%autoreload 2"
   ],
   "id": "9b8f4360f956b974",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Imports",
   "id": "53bce69ec8ae7cf3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from warnings import catch_warnings\n",
    "\n",
    "from data.api import UcIrvineAPI, UcIrvineDatasetIDs, BureauEconomicAnalysisAPI\n",
    "import pandas\n",
    "import json"
   ],
   "id": "50dcaedca9e6cb83",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "pandas.set_option('display.max_colwidth', None)  # show all text in cells\n",
    "#pandas.set_option(\"display.max_rows\", 100_000)\n",
    "pandas.options.mode.copy_on_write = True"
   ],
   "id": "dd9fc7ed6aee7e27",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# UcIrvine Data",
   "id": "418a7487f08fecdd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "uci = UcIrvineAPI.fetch_dataset(repo_id=UcIrvineDatasetIDs.Apartment_For_Rent_Classified.value)",
   "id": "fbc121e30a2defb3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "uci_df:pandas.DataFrame = uci.data.original.reset_index()",
   "id": "cd4d00ffcffe3413",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#TODO MOVE BACK TO WRANGLINGS_UTILS.PY\n",
    "import re\n",
    "\n",
    "\n",
    "class BadDataException(ValueError, TypeError):\n",
    "    \"\"\"Raised when int(x) fails; behaves like both ValueError and TypeError.\"\"\"\n",
    "\n",
    "    def __init__(self, value, message=None):\n",
    "        self.value = value\n",
    "        super().__init__(message)\n",
    "\n",
    "\n",
    "BAD_DATA = {\n",
    "    \"id\": [],\n",
    "    \"category\": [],\n",
    "    \"title\": [],\n",
    "    \"body\": [],\n",
    "    \"amenities\": [],\n",
    "    \"bathrooms\": [],\n",
    "    \"bedrooms\": [],\n",
    "    \"currency\": [],\n",
    "    \"fee\": [],\n",
    "    \"has_photo\": [],\n",
    "    \"pets_allowed\": [],\n",
    "    \"price\": [],\n",
    "    \"price_display\": [],\n",
    "    \"price_type\": [],\n",
    "    \"square_feet\": [],\n",
    "    \"address\": [],\n",
    "    \"cityname\": [],\n",
    "    \"state\": [],\n",
    "    \"latitude\": [],\n",
    "    \"longitude\": [],\n",
    "    \"source\": [],\n",
    "    \"time\": []\n",
    "}\n",
    "\n",
    "# Common state/territory abbreviations to exclude when they appear alone as the \"city\"\n",
    "US_STATE_ABBR = {\n",
    "    \"AL\",\"AK\",\"AZ\",\"AR\",\"CA\",\"CO\",\"CT\",\"DE\",\"FL\",\"GA\",\"HI\",\"ID\",\"IL\",\"IN\",\"IA\",\"KS\",\"KY\",\"LA\",\"ME\",\"MD\",\"MA\",\"MI\",\n",
    "    \"MN\",\"MS\",\"MO\",\"MT\",\"NE\",\"NV\",\"NH\",\"NJ\",\"NM\",\"NY\",\"NC\",\"ND\",\"OH\",\"OK\",\"OR\",\"PA\",\"RI\",\"SC\",\"SD\",\"TN\",\"TX\",\"UT\",\n",
    "    \"VT\",\"VA\",\"WA\",\"WV\",\"WI\",\"WY\",\"DC\",\"PR\",\"VI\",\"GU\",\"AS\",\"MP\"\n",
    "}\n",
    "\n",
    "# Patterns we consider invalid for a city field\n",
    "URL_PAT       = re.compile(r\"(?:https?://|www\\.|\\.(?:com|net|org|edu|gov|io|co|us)\\b)\", re.I)\n",
    "COORD_PAIR    = re.compile(r\"^\\s*-?\\d+(?:\\.\\d+)?\\s*[, ]\\s*-?\\d+(?:\\.\\d+)?\\s*$\")  # \"40.7, -73.9\" or \"40.7 -73.9\"\n",
    "NUM_ONLY      = re.compile(r\"^\\s*-?\\d+(?:\\.\\d+)?\\s*$\")\n",
    "ALLOWED_CHARS = re.compile(r\"^[A-Za-z .'\\-]+$\")  # letters, spaces, ., apostrophe, hyphen\n",
    "\n",
    "# Expand common city-name abbreviations when they start the city token\n",
    "ABBREV_MAP = {\n",
    "    \"st\": \"saint\", \"st.\": \"saint\",\n",
    "    \"ft\": \"fort\",  \"ft.\": \"fort\",\n",
    "    \"mt\": \"mount\", \"mt.\": \"mount\",\n",
    "}\n",
    "\n",
    "def _expand_leading_abbrev(s: str) -> str:\n",
    "    # Expand only if the *first* token is an abbreviation (e.g., \"St Louis\" -> \"Saint Louis\")\n",
    "    tokens = s.split()\n",
    "    if not tokens:\n",
    "        return s\n",
    "    first = tokens[0].lower().strip(\".,\")\n",
    "    if first in ABBREV_MAP:\n",
    "        tokens[0] = ABBREV_MAP[first]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "def clean_id(x):\n",
    "    try:\n",
    "        try:\n",
    "            return int(x)\n",
    "        except Exception:\n",
    "            raise BadDataException(x)\n",
    "    except BadDataException as e:\n",
    "        BAD_DATA[\"id\"].append(e.value)\n",
    "        return None\n",
    "    except Exception:\n",
    "        BAD_DATA[\"id\"].append(x)\n",
    "        return None\n",
    "\n",
    "def clean_category(x):\n",
    "    try:\n",
    "        x = str(x).lower().strip()\n",
    "        parts = x.split('/')\n",
    "\n",
    "        cleaned_parts = [\n",
    "            re.sub(r'^(ousing|ing)', 'housing', p.strip())\n",
    "            for p in parts\n",
    "        ]\n",
    "\n",
    "        if any(p == '2' for p in cleaned_parts):\n",
    "            raise BadDataException(cleaned_parts)\n",
    "\n",
    "        return cleaned_parts\n",
    "\n",
    "    except BadDataException as e:\n",
    "        BAD_DATA[\"category\"].append(e.value)\n",
    "        return None\n",
    "    except Exception:\n",
    "        BAD_DATA[\"category\"].append(x)\n",
    "        return None\n",
    "\n",
    "def clean_title(x):\n",
    "    try:\n",
    "        return str(x)\n",
    "    except BadDataException as e:\n",
    "        BAD_DATA[\"title\"].append(e.value)\n",
    "        return None\n",
    "    except Exception:\n",
    "        BAD_DATA[\"title\"].append(x)\n",
    "        return None\n",
    "\n",
    "\n",
    "def clean_body(x):\n",
    "    try:\n",
    "        return str(x)\n",
    "    except BadDataException as e:\n",
    "        BAD_DATA[\"body\"].append(e.value)\n",
    "        return None\n",
    "\n",
    "\n",
    "def clean_amenities(x):\n",
    "    try:\n",
    "        # Convert to string and lowercase\n",
    "        x = str(x).lower().strip()\n",
    "\n",
    "        # Split first by '/', then flatten any comma-separated pieces\n",
    "        raw_parts = []\n",
    "        for part in x.split('/'):\n",
    "            raw_parts.extend(part.split(','))\n",
    "\n",
    "        # Clean and filter empty values\n",
    "        cleaned_parts = [p.strip() for p in raw_parts if p.strip()]\n",
    "\n",
    "        if any(p == 'nan' for p in cleaned_parts):\n",
    "            raise BadDataException(cleaned_parts, 'nan')\n",
    "\n",
    "        return cleaned_parts\n",
    "\n",
    "    except BadDataException as e:\n",
    "        BAD_DATA[\"amenities\"].append(e.value)\n",
    "        return None\n",
    "    except Exception:\n",
    "        BAD_DATA[\"amenities\"].append(x)\n",
    "        return None\n",
    "\n",
    "def clean_bathrooms(x):\n",
    "    try:\n",
    "        # Normalize to lowercase string\n",
    "        val = str(x).strip().lower()\n",
    "\n",
    "        # If the value is invalid, raise your custom exception\n",
    "        if val in {\"nan\", \"no\", \"thumbnail\"}:\n",
    "            raise BadDataException(x)\n",
    "\n",
    "        # Try converting to integer\n",
    "        return int(float(val))  # handles '2.0' etc.\n",
    "\n",
    "    except BadDataException as e:\n",
    "        BAD_DATA[\"bathrooms\"].append(e.value)\n",
    "        return None\n",
    "    except Exception:\n",
    "        BAD_DATA[\"bathrooms\"].append(x)\n",
    "        return None\n",
    "\n",
    "def clean_bedrooms(x):\n",
    "    try:\n",
    "        # Normalize value to lowercase string\n",
    "        val = str(x).strip().lower()\n",
    "\n",
    "        # Raise custom exception for clearly invalid values\n",
    "        if val in {\"nan\", \"no\", \"thumbnail\", \"cats,dogs\"}:\n",
    "            raise BadDataException(x)\n",
    "\n",
    "        # Attempt numeric conversion (handles \"2.0\" etc.)\n",
    "        return int(float(val))\n",
    "\n",
    "    except BadDataException as e:\n",
    "        BAD_DATA[\"bedrooms\"].append(e.value)\n",
    "        return None\n",
    "    except Exception:\n",
    "        BAD_DATA[\"bedrooms\"].append(x)\n",
    "        return None\n",
    "\n",
    "def clean_currency(x):\n",
    "    try:\n",
    "        # Normalize value to lowercase string\n",
    "        val = str(x).strip().upper()  # currency codes are uppercase by convention\n",
    "\n",
    "        # Define acceptable currency codes\n",
    "        valid_currencies = {\"USD\"}\n",
    "\n",
    "        # Raise if not valid\n",
    "        if val not in valid_currencies:\n",
    "            raise BadDataException(x)\n",
    "\n",
    "        return val\n",
    "\n",
    "    except BadDataException as e:\n",
    "        BAD_DATA[\"currency\"].append(e.value)\n",
    "        return None\n",
    "    except Exception:\n",
    "        BAD_DATA[\"currency\"].append(x)\n",
    "        return None\n",
    "\n",
    "def clean_fee(x):\n",
    "    try:\n",
    "        # Normalize value\n",
    "        val = str(x).strip().lower()\n",
    "\n",
    "        # Map valid values\n",
    "        if val == \"yes\":\n",
    "            return True\n",
    "        elif val == \"no\":\n",
    "            return False\n",
    "\n",
    "        raise BadDataException(x)\n",
    "\n",
    "    except BadDataException as e:\n",
    "        BAD_DATA[\"fee\"].append(e.value)\n",
    "        return None\n",
    "\n",
    "    except Exception:\n",
    "        BAD_DATA[\"fee\"].append(x)\n",
    "        return None\n",
    "\n",
    "\n",
    "def clean_has_photo(x):\n",
    "    try:\n",
    "        # Normalize value\n",
    "        val = str(x).strip().lower()\n",
    "\n",
    "        # Map known valid values\n",
    "        if val in {\"yes\", \"thumbnail\"}:\n",
    "            return True\n",
    "        elif val == \"no\":\n",
    "            return False\n",
    "\n",
    "        # Anything else is bad data\n",
    "        raise BadDataException(x)\n",
    "\n",
    "    except BadDataException as e:\n",
    "        BAD_DATA[\"has_photo\"].append(e.value)\n",
    "        return None\n",
    "    except Exception:\n",
    "        BAD_DATA[\"has_photo\"].append(x)\n",
    "        return None\n",
    "\n",
    "def clean_pets_allowed(x):\n",
    "    try:\n",
    "        val = str(x).strip().lower()\n",
    "\n",
    "        # Handle truly missing or numeric data (bad)\n",
    "        if val == \"nan\" or val.isnumeric():\n",
    "            raise BadDataException(x)\n",
    "\n",
    "        # Split on commas or slashes\n",
    "        tokens = [t.strip() for t in re.split(r\"[,/]\", val) if t.strip()]\n",
    "\n",
    "        has_cats = any(t == \"cats\" for t in tokens)\n",
    "        has_dogs = any(t == \"dogs\" for t in tokens)\n",
    "        has_none = any(t == \"none\" for t in tokens)\n",
    "\n",
    "        # Determine clean category\n",
    "        if has_cats and has_dogs:\n",
    "            return \"Cats&Dogs\"\n",
    "        if has_cats:\n",
    "            return \"Cats\"\n",
    "        if has_dogs:\n",
    "            return \"Dogs\"\n",
    "        if has_none:\n",
    "            return \"X\"  # ‚Üê keep as string 'None', not Python None\n",
    "\n",
    "\n",
    "    except BadDataException as e:\n",
    "        BAD_DATA[\"pets_allowed\"].append(e.value)\n",
    "        return None\n",
    "    except Exception:\n",
    "        BAD_DATA[\"pets_allowed\"].append(x)\n",
    "        return None\n",
    "\n",
    "def clean_price(x):\n",
    "    try:\n",
    "        return float(x)\n",
    "    except BadDataException as e:\n",
    "        BAD_DATA[\"price\"].append(e.value)\n",
    "        return None\n",
    "    except Exception:\n",
    "        BAD_DATA[\"price\"].append(x)\n",
    "        return None\n",
    "\n",
    "def clean_price_display(x):\n",
    "    try:\n",
    "        if x is None:\n",
    "            print(f\"found None {x}\")\n",
    "            raise BadDataException(x)\n",
    "\n",
    "        val = str(x).strip()\n",
    "\n",
    "        # --- Detect \"Weekly\" / \"Monthly\" and print ---\n",
    "        if re.search(r'\\b(weekly|monthly)\\b', val, flags=re.IGNORECASE):\n",
    "            pass\n",
    "            # print(f\"found recurring term {x}\")\n",
    "\n",
    "        # --- Remove $ signs, commas, and spaces ---\n",
    "        val = val.replace(\"$\", \"\").replace(\",\", \"\").strip()\n",
    "\n",
    "        # --- Extract numeric parts ---\n",
    "        range_match = re.findall(r\"[\\d.]+\", val)\n",
    "        if len(range_match) == 0:\n",
    "            #print(f\"found non numeric term {x}\")\n",
    "            raise BadDataException(x)\n",
    "        elif len(range_match) == 1:\n",
    "            return float(range_match[0])\n",
    "        else:\n",
    "            #print(f\"averaging terms {range_match=}\")\n",
    "            nums = [float(v) for v in range_match]\n",
    "            return sum(nums) / len(nums)\n",
    "\n",
    "    except BadDataException as e:\n",
    "        BAD_DATA[\"price_display\"].append(e.value)\n",
    "        return None\n",
    "    except Exception:\n",
    "        BAD_DATA[\"price_display\"].append(x)\n",
    "        return None\n",
    "\n",
    "def clean_price_type(x):\n",
    "    try:\n",
    "        val = str(x).strip().lower()\n",
    "\n",
    "        # Valid categories\n",
    "        if \"monthly\" in val:\n",
    "            return \"monthly\"\n",
    "        elif \"weekly\" in val:\n",
    "            return \"weekly\"\n",
    "\n",
    "        #print(f\"found {x}\")\n",
    "        raise BadDataException(x, \" i cant intepret\")\n",
    "\n",
    "    except BadDataException as e:\n",
    "        BAD_DATA[\"price_type\"].append(e.value)\n",
    "        return None\n",
    "    except Exception:\n",
    "        BAD_DATA[\"price_type\"].append(x)\n",
    "        return None\n",
    "\n",
    "def clean_square_feet(x):\n",
    "    try:\n",
    "        # Treat None and float('nan') as invalid\n",
    "        if x is None:\n",
    "            raise BadDataException(x)\n",
    "\n",
    "        val = str(x).strip()\n",
    "\n",
    "        # Detect values that contain only numbers or a decimal\n",
    "        match = re.fullmatch(r\"\\d+(?:\\.\\d+)?\", val)\n",
    "        if match:\n",
    "            return float(val)\n",
    "\n",
    "        #print(f\"found {x}\")\n",
    "        raise BadDataException(x)\n",
    "\n",
    "    except BadDataException as e:\n",
    "        BAD_DATA[\"square_feet\"].append(e.value)\n",
    "        return None\n",
    "    except Exception:\n",
    "        BAD_DATA[\"square_feet\"].append(x)\n",
    "        return None\n",
    "\n",
    "def clean_address(x):\n",
    "    try:\n",
    "        #TODO\n",
    "        # --- Handle missing / NaN values ---\n",
    "        if x is None:\n",
    "            raise BadDataException(x)\n",
    "\n",
    "        val = str(x).strip()\n",
    "\n",
    "        # --- Handle explicit invalid tokens ---\n",
    "        if val.lower() in {\"\", \"none\", \"nan\"}:\n",
    "            raise BadDataException(val)\n",
    "\n",
    "        # --- Reject coordinate-like values (e.g., \"40.2659 -77.4948\") ---\n",
    "        if re.fullmatch(r\"^-?\\d+(\\.\\d+)?\\s*[,\\s]\\s*-?\\d+(\\.\\d+)?$\", val):\n",
    "            raise BadDataException(val)\n",
    "\n",
    "        # --- Reject numeric-only or \"square feet\" type values ---\n",
    "        if re.fullmatch(r\"[\\d., ]+$\", val) or \"square\" in val.lower() or \"sq\" in val.lower():\n",
    "            raise BadDataException(val)\n",
    "\n",
    "        # --- Basic address sanity check: must contain both a number and a letter ---\n",
    "        if not (re.search(r\"\\d\", val) and re.search(r\"[A-Za-z]\", val)):\n",
    "            raise BadDataException(val)\n",
    "\n",
    "        # --- Normalize whitespace and punctuation ---\n",
    "        cleaned = re.sub(r\"\\s+\", \" \", val).strip(\" ,.;-\")\n",
    "\n",
    "        return cleaned\n",
    "\n",
    "    except BadDataException as e:\n",
    "        BAD_DATA[\"address\"].append(e.value)\n",
    "        return None\n",
    "    except Exception:\n",
    "        BAD_DATA[\"address\"].append(x)\n",
    "        return None\n",
    "\n",
    "def clean_city_name(x):\n",
    "    try:\n",
    "        # Missing/NaN\n",
    "        if x is None:\n",
    "            raise BadDataException(None)\n",
    "\n",
    "        raw = str(x)\n",
    "        s = raw.strip()\n",
    "        if s == \"\" or s.lower() in {\"nan\", \"none\", \"null\", \"n/a\"}:\n",
    "            raise BadDataException(raw)\n",
    "\n",
    "        # Hard rejections: urls/domains, coordinates, pure numbers, pure state codes\n",
    "        if URL_PAT.search(s):\n",
    "            raise BadDataException(raw)\n",
    "        if COORD_PAIR.match(s) or NUM_ONLY.match(s):\n",
    "            raise BadDataException(raw)\n",
    "        if s.upper() in US_STATE_ABBR:\n",
    "            raise BadDataException(raw)\n",
    "\n",
    "        # Reject if it contains digits (city names should not contain numerals)\n",
    "        if any(ch.isdigit() for ch in s):\n",
    "            raise BadDataException(raw)\n",
    "\n",
    "        # Keep only plausible characters\n",
    "        if not ALLOWED_CHARS.match(s):\n",
    "            raise BadDataException(raw)\n",
    "\n",
    "        # Normalize internal whitespace & punctuation spacing\n",
    "        s = re.sub(r\"\\s+\", \" \", s).strip(\" ,.;-\")\n",
    "\n",
    "        # Expand leading abbreviations like St./Ft./Mt.\n",
    "        s = _expand_leading_abbrev(s)\n",
    "\n",
    "        # Title-case: keep nice formatting like \"Saint Paul\", \"Fort Worth\", \"O'Fallon\", \"Coeur d'Alene\"\n",
    "        s = \" \".join(\n",
    "            part if part.isupper() and len(part) <= 3  # keep short all-caps (e.g., \"DC\") as-is if they appear\n",
    "            else part.capitalize()\n",
    "            for part in re.split(r\"(\\s+)\", s)          # preserve spacing while capitalizing tokens\n",
    "        )\n",
    "\n",
    "        # Final sanity: must contain letters and at least 2 characters\n",
    "        if not re.search(r\"[A-Za-z]\", s) or len(s) < 2:\n",
    "            raise BadDataException(raw)\n",
    "\n",
    "        return s\n",
    "\n",
    "    except BadDataException as e:\n",
    "        BAD_DATA[\"cityname\"].append(e.value)\n",
    "        return None\n",
    "    except Exception:\n",
    "        BAD_DATA[\"cityname\"].append(x)\n",
    "        return None\n",
    "\n",
    "def clean_state(x):\n",
    "    #TODO:\n",
    "    try:\n",
    "        print(x)\n",
    "        return str(x)\n",
    "    except BadDataException as e:\n",
    "        BAD_DATA[\"state\"].append(e.value)\n",
    "        return None\n",
    "\n",
    "\n",
    "def clean_latitude(x):\n",
    "    #TODO:\n",
    "    try:\n",
    "        print(x)\n",
    "        return float(x)\n",
    "    except BadDataException as e:\n",
    "        BAD_DATA[\"latitude\"].append(e.value)\n",
    "        return None\n",
    "\n",
    "\n",
    "def clean_longitude(x):\n",
    "    #TODO:\n",
    "    try:\n",
    "        print(x)\n",
    "        return float(x)\n",
    "    except BadDataException as e:\n",
    "        BAD_DATA[\"longitude\"].append(e.value)\n",
    "        return None\n",
    "\n",
    "\n",
    "def clean_source(x):\n",
    "    #TODO:\n",
    "    try:\n",
    "        print(x)\n",
    "        return str(x)\n",
    "    except BadDataException as e:\n",
    "        BAD_DATA[\"source\"].append(e.value)\n",
    "        return None\n",
    "\n",
    "\n",
    "def clean_time(x):\n",
    "    #TODO:\n",
    "    try:\n",
    "        print(x)\n",
    "        return str(x)\n",
    "    except BadDataException as e:\n",
    "        BAD_DATA[\"time\"].append(e.value)\n",
    "        return None\n",
    "\n",
    "\n",
    "cleaned_uci_df = pandas.DataFrame()\n",
    "cleaned_uci_df['id'] = uci_df['id'].apply(clean_id)\n",
    "cleaned_uci_df['category'] = uci_df['category'].apply(clean_category)\n",
    "cleaned_uci_df['title'] = uci_df['title']  #.apply(clean_title)\n",
    "cleaned_uci_df['body'] = uci_df['body']  #.apply(clean_body)\n",
    "cleaned_uci_df['amenities'] = uci_df['amenities'].apply(clean_amenities)\n",
    "cleaned_uci_df['bathrooms'] = uci_df['bathrooms'].apply(clean_bathrooms)\n",
    "cleaned_uci_df['bedrooms'] = uci_df['bedrooms'].apply(clean_bedrooms)\n",
    "cleaned_uci_df['currency'] = uci_df['currency'].apply(clean_currency)\n",
    "cleaned_uci_df['fee'] = uci_df['fee'].apply(clean_fee)\n",
    "cleaned_uci_df['has_photo'] = uci_df['has_photo'].apply(clean_has_photo)\n",
    "cleaned_uci_df['pets_allowed'] = uci_df['pets_allowed'].apply(clean_pets_allowed)\n",
    "cleaned_uci_df['price'] = uci_df['price'].apply(clean_price)\n",
    "cleaned_uci_df['price_display'] = uci_df['price_display'].apply(clean_price_display)\n",
    "cleaned_uci_df['price_type'] = uci_df['price_type'].apply(clean_price_type)\n",
    "cleaned_uci_df['square_feet'] = uci_df['square_feet'].apply(clean_square_feet)\n",
    "#cleaned_uci_df['address'] = uci_df['address'].apply(clean_address)\n",
    "cleaned_uci_df['cityname'] = uci_df['cityname'].apply(clean_city_name)\n",
    "# cleaned_uci_df['state'] = uci_df['state'].apply(clean_state)\n",
    "# cleaned_uci_df['latitude'] = uci_df['latitude'].apply(clean_latitude)\n",
    "# cleaned_uci_df['longitude'] = uci_df['longitude'].apply(clean_longitude)\n",
    "# cleaned_uci_df['source'] = uci_df['source'].apply(clean_source)\n",
    "# cleaned_uci_df['time'] = uci_df['time'].apply(clean_time)\n",
    "#cleaned_uci_df"
   ],
   "id": "f32b8057f16c161a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "pandas.set_option(\"display.max_rows\", 100_000) # TOGGLE  UN/COMMENT\n",
    "#pandas.reset_option(\"display.max_rows\") # TOGGLE UN/COMMENT\n",
    "cleaned_uci_df['cityname'].value_counts(dropna=False)# change column"
   ],
   "id": "e3f9bd72886556f5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#DONT DELETE MIGHT NEED\n",
    "#s = cleaned_uci_df['bathrooms'].explode()\n",
    "#global_counts = s.value_counts().to_dict()\n",
    "#global_counts"
   ],
   "id": "b8d3584b5226cf12",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(f'BAD_DATA: {json.dumps(BAD_DATA['cityname'], indent=2)}') # CHANGE COL",
   "id": "d6dca21e6ef2a4d8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "fef3e6ddec719994",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "b312f60c9bf3825c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from data.wrangling_utils import STATE_MAP\n",
    "\n",
    "uci_df[\"state_full\"] = uci_df[\"state\"].str.upper().map(STATE_MAP)\n",
    "print(uci_df.shape)\n",
    "uci_df.dropna(subset=[\"state_full\"], inplace=True)\n",
    "uci_df.shape"
   ],
   "id": "6d27fe052af36984",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Bureau of Economic Data",
   "id": "319eaed296f87a8d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "bea_df = BureauEconomicAnalysisAPI.fetch_dataset('Regional', GeoFips='STATE', TableName='SARPP', Year='2019',\n",
    "                                                 LineCode='1')"
   ],
   "id": "db254e66461c17a8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# Merge Data",
   "id": "473b1c04501be141",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "merged = pandas.merge(\n",
    "    uci_df,\n",
    "    bea_df,\n",
    "    left_on=\"state_full\",\n",
    "    right_on=\"GeoName\",\n",
    "    how=\"inner\"\n",
    ")\n",
    "merged.shape"
   ],
   "id": "5824c8eca26f795f",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
